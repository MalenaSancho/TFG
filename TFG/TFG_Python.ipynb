{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "6d45675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ISLP in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.20 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (2.1.4)\n",
      "Requirement already satisfied: lxml in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (4.9.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (1.2.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (0.14.0)\n",
      "Requirement already satisfied: lifelines in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (0.30.0)\n",
      "Requirement already satisfied: pygam in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (0.9.1)\n",
      "Requirement already satisfied: torch in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (2.7.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (2.5.1.post0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from ISLP) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pandas>=0.20->ISLP) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pandas>=0.20->ISLP) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pandas>=0.20->ISLP) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from scikit-learn>=1.2->ISLP) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from statsmodels>=0.13->ISLP) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from statsmodels>=0.13->ISLP) (23.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from lifelines->ISLP) (3.8.0)\n",
      "Requirement already satisfied: autograd>=1.5 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from lifelines->ISLP) (1.8.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from lifelines->ISLP) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from lifelines->ISLP) (1.1.1)\n",
      "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pygam->ISLP) (4.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pytorch-lightning->ISLP) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pytorch-lightning->ISLP) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pytorch-lightning->ISLP) (4.13.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from pytorch-lightning->ISLP) (0.14.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from torch->ISLP) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from torch->ISLP) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from torch->ISLP) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from torch->ISLP) (3.1.3)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.9.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (68.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13->ISLP) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from sympy>=1.13.3->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning->ISLP) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from jinja2->torch->ISLP) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: l0bnb in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from l0bnb) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from l0bnb) (1.11.4)\n",
      "Requirement already satisfied: numba>=0.53.1 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from l0bnb) (0.59.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\usuario\\documents\\python scripts\\lib\\site-packages (from numba>=0.53.1->l0bnb) (0.42.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ISLP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.api import add_constant\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import Stepwise \n",
    "from ISLP.models import sklearn_selected\n",
    "from ISLP.models import sklearn_selection_path\n",
    "\n",
    "%pip install l0bnb\n",
    "from l0bnb import fit_path\n",
    "\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "50a58b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  Progression  \n",
       "0 -0.002592  0.019907 -0.017646        151.0  \n",
       "1 -0.039493 -0.068332 -0.092204         75.0  \n",
       "2 -0.002592  0.002861 -0.025930        141.0  \n",
       "3  0.034309  0.022688 -0.009362        206.0  \n",
       "4 -0.002592 -0.031988 -0.046641        135.0  "
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset de Diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Crear un DataFrame con los datos\n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Agregar la columna de etiquetas (progresión de la diabetes)\n",
    "df_diabetes['Progression'] = diabetes.target\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "f9f01829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(df_diabetes['Progression']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09d9bc",
   "metadata": {},
   "source": [
    "### División del DataSet Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "070874fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos\n",
    "y = np.array(df_diabetes['Progression'])\n",
    "X = df_diabetes.drop('Progression', axis=1)  # Mantén X como un DataFrame\n",
    "\n",
    "\n",
    "#Dividir en entrenamiento, validación y prueba\n",
    "pct_val = 0.20\n",
    "pct_test = 0.10\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=pct_test, random_state=100)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=pct_val/(1-pct_test), random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931bf8b",
   "metadata": {},
   "source": [
    "### Elección del modelo óptimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954a9c2",
   "metadata": {},
   "source": [
    "##### Cp de Mallows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "4b1f47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cp de Mallows del modelo reducido:             3712.2905\n",
      "Cp_alternativa de Mallows del modelo reducido: 75.6615\n"
     ]
    }
   ],
   "source": [
    "# Modelo reducido: usaremos solo las primeras 4 variables como ejemplo\n",
    "selected_features = ['age', 'sex', 'bmi', 'bp'] \n",
    "\n",
    "def Cp(X_train, y_train, selected_features):\n",
    "\n",
    "    n = len(y_train)\n",
    "\n",
    "    # Modelo completo para estimar sigma^2\n",
    "    X_train_full = sm.add_constant(X_train)\n",
    "    model_full = OLS(y_train, X_train_full).fit()\n",
    "    sigma2_hat=model_full.scale\n",
    "\n",
    "    # Modelo reducido:\n",
    "    X_train_reduced = sm.add_constant(X_train[selected_features])  \n",
    "    model_reduced = OLS(y_train, X_train_reduced).fit()\n",
    "    rss_reduced = np.sum(model_reduced.resid ** 2)\n",
    "    d_reduced = len(model_reduced.params)\n",
    "\n",
    "    # Cp de Mallows\n",
    "    Cp = (rss_reduced + 2 * d_reduced * sigma2_hat) / n\n",
    "\n",
    "    return Cp\n",
    "\n",
    "def Cp_alternativa(X_train, y_train, selected_features):\n",
    "    \n",
    "    n = len(y_train)\n",
    "\n",
    "    # Modelo completo para estimar sigma^2\n",
    "    X_train_full = sm.add_constant(X_train)\n",
    "    model_full = OLS(y_train, X_train_full).fit()\n",
    "    sigma2_hat = model_full.scale\n",
    "\n",
    "    # Modelo reducido:\n",
    "    X_train_reduced = sm.add_constant(X_train[selected_features])  \n",
    "    model_reduced = OLS(y_train, X_train_reduced).fit()\n",
    "    rss_reduced = np.sum(model_reduced.resid ** 2)\n",
    "    d_reduced = len(model_reduced.params) \n",
    "\n",
    "    # Cp de Mallows\n",
    "    Cp_alternativa = (rss_reduced / sigma2_hat) - (n - 2 * d_reduced)\n",
    "\n",
    "    return Cp_alternativa\n",
    "\n",
    "print(f\"Cp de Mallows del modelo reducido:             {Cp(X_train, y_train, selected_features):.4f}\")\n",
    "print(f\"Cp_alternativa de Mallows del modelo reducido: {Cp_alternativa(X_train, y_train, selected_features):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fa090",
   "metadata": {},
   "source": [
    "sm.add_constant() agrega una columna de unos al inicio de la matriz de predictores. Esa columna representa el término independiente (intercepto) del modelo de regresión. Es necesario porque statsmodels.OLS no incluye automáticamente un intercepto, a diferencia de scikit-learn. Por eso hay que agregarlo manualmente si queremos que el modelo tenga un término constante. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428cdbc8",
   "metadata": {},
   "source": [
    "### AIC, BIC y $R^{2}$ ajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3a3f6",
   "metadata": {},
   "source": [
    "Lo podemos calcular de manera manual utilizando la fórmula que aproximación para modelos lineales de AIC/BIC o utilizar statsmodels, ya que tiene incluido el calculo de AIC/BIC utilizando la verosimilitud del modelo reducido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "0439bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Cálculos Manuales ---------\n",
      "AIC manual:              3734.8555\n",
      "BIC manual:              3957.4015\n",
      "R² ajustado (manual):    0.3734\n",
      "\n",
      "----------- Statsmodels -------------\n",
      "AIC (statsmodels):       3407.5083\n",
      "BIC (statsmodels):       3426.1588\n",
      "R² ajustado (stats):     0.3734\n"
     ]
    }
   ],
   "source": [
    "def aic_manual(X_train, y_train, selected_features):\n",
    "    X_train_red = sm.add_constant(X_train[selected_features])\n",
    "\n",
    "    # Ajustar modelo OLS\n",
    "    model = sm.OLS(y_train, X_train_red).fit()\n",
    "\n",
    "    # --- Cálculos manuales ---\n",
    "    n = len(y_train)                            # número de observaciones\n",
    "    d = len(model.params)                       # número de parámetros\n",
    "    rss = np.sum(model.resid ** 2)\n",
    "\n",
    "    # AIC: AIC = (RSS + 2 * d * sigma^2) / n\n",
    "    sigma2_hat = rss / (n - d)\n",
    "    aic_manual = (rss + 2 * d * sigma2_hat) / n\n",
    "\n",
    "    return aic_manual\n",
    "\n",
    "def bic_manual(X_train, y_train, selected_features):\n",
    "    X_train_red = sm.add_constant(X_train[selected_features])\n",
    "\n",
    "    # Ajustar modelo OLS\n",
    "    model = sm.OLS(y_train, X_train_red).fit()\n",
    "\n",
    "    # --- Cálculos manuales ---\n",
    "    n = len(y_train)                            # número de observaciones\n",
    "    d = len(model.params)                       # número de parámetros\n",
    "    rss = np.sum(model.resid ** 2)\n",
    "\n",
    "    # BIC: BIC = (RSS + log(n) * d * sigma^2) / n\n",
    "    sigma2_hat = rss / (n - d)\n",
    "    bic_manual = (rss + np.log(n) * d * sigma2_hat) / n\n",
    "\n",
    "    return bic_manual\n",
    "\n",
    "\n",
    "def r2_adj_manual(X_train, y_train, selected_features):\n",
    "    X_train_red = sm.add_constant(X_train[selected_features])\n",
    "\n",
    "    # Ajustar modelo OLS\n",
    "    model = sm.OLS(y_train, X_train_red).fit()\n",
    "\n",
    "    # --- Cálculos manuales ---\n",
    "    n = len(y_train)                            # número de observaciones\n",
    "    d = len(model.params) - 1                     # número de parámetros, ya que model.params incluye el intercepto\n",
    "    y_mean = np.mean(y_train)\n",
    "    rss = np.sum(model.resid ** 2)\n",
    "    tss = np.sum((y_train - y_mean)**2)\n",
    "\n",
    "    # R² ajustado: R2_adj = 1 - (RSS / (n - d - 1)) / (TSS / (n - 1))\n",
    "    r2_adj_manual = 1 - (rss / (n - d - 1)) / (tss / (n - 1))\n",
    "\n",
    "    return r2_adj_manual\n",
    "\n",
    "\n",
    "# --- Comparación con statsmodels ---\n",
    "X_train_red = sm.add_constant(X_train[selected_features])\n",
    "model = sm.OLS(y_train, X_train_red).fit()\n",
    "aic = model.aic\n",
    "bic = model.bic\n",
    "r2_adj = model.rsquared_adj\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"--------- Cálculos Manuales ---------\")\n",
    "print(f\"AIC manual:              {aic_manual(X_train, y_train, selected_features):.4f}\")\n",
    "print(f\"BIC manual:              {bic_manual(X_train, y_train, selected_features):.4f}\")\n",
    "print(f\"R² ajustado (manual):    {r2_adj_manual(X_train, y_train, selected_features):.4f}\")\n",
    "\n",
    "print(\"\\n----------- Statsmodels -------------\")\n",
    "print(f\"AIC (statsmodels):       {aic:.4f}\")\n",
    "print(f\"BIC (statsmodels):       {bic:.4f}\")\n",
    "print(f\"R² ajustado (stats):     {r2_adj:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30f5df",
   "metadata": {},
   "source": [
    "### Validación y validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d5d6e",
   "metadata": {},
   "source": [
    "##### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "6c6fa85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE de validación: 3525.98\n"
     ]
    }
   ],
   "source": [
    "def validación(X_train, y_train, X_val, y_val, selected_features):\n",
    "    X_train_red = sm.add_constant(X_train[selected_features])\n",
    "    model = sm.OLS(y_train, X_train_red).fit()\n",
    "    X_val_reduced = sm.add_constant(X_val[selected_features]) \n",
    "    y_val_pred=model.predict(X_val_reduced)\n",
    "    MSE=mean_squared_error(y_val,y_val_pred)\n",
    "    return MSE\n",
    "\n",
    "print(f\"MSE de validación: {validación(X_train, y_train, X_val, y_val, selected_features):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b42d3",
   "metadata": {},
   "source": [
    "##### Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "fc7eaa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Validación cruzada (5-fold) =====\n",
      "MSE por fold: [3262.51 2882.93 4001.65 4293.86 3806.08]\n",
      "MSE medio (CV): 3649.4049\n",
      "\n",
      "===== Mejor modelo =====\n",
      "Mejor MSE: 2882.9292\n",
      "Coeficientes del mejor modelo:\n",
      "const    153.317590\n",
      "age       70.156920\n",
      "sex      -65.120369\n",
      "bmi      817.613689\n",
      "bp       356.031748\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def validacion_cruzada(X, y, selected_features, k):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=100)\n",
    "    mse_scores = []\n",
    "    best_mse = float('inf')\n",
    "    best_model_coefs = None\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_ktrain, X_kval = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_ktrain, y_kval = y[train_index], y[val_index]\n",
    "\n",
    "        # Reducción y constante\n",
    "        X_ktrain_red = sm.add_constant(X_ktrain[selected_features])\n",
    "        X_kval_red = sm.add_constant(X_kval[selected_features])\n",
    "\n",
    "        model_k = sm.OLS(y_ktrain, X_ktrain_red).fit()\n",
    "        y_pred_k = model_k.predict(X_kval_red)\n",
    "        mse_k = mean_squared_error(y_kval, y_pred_k)\n",
    "        mse_scores.append(mse_k)\n",
    "\n",
    "        # Actualizar si es el mejor modelo\n",
    "        if mse_k < best_mse:\n",
    "            best_mse = mse_k\n",
    "            best_model_coefs = model_k.params\n",
    "\n",
    "    return best_model_coefs, best_mse, mse_scores\n",
    "\n",
    "k=5\n",
    "vc=validacion_cruzada(X, y, selected_features, k=5)\n",
    "\n",
    "print(\"\\n===== Validación cruzada ({}-fold) =====\".format(k))\n",
    "print(\"MSE por fold:\", np.round(vc[2], 2))\n",
    "print(f\"MSE medio (CV): {np.mean(vc[2]):.4f}\")\n",
    "\n",
    "print(\"\\n===== Mejor modelo =====\")\n",
    "print(f\"Mejor MSE: {vc[1]:.4f}\")\n",
    "print(\"Coeficientes del mejor modelo:\")\n",
    "print(vc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e40ba7",
   "metadata": {},
   "source": [
    "# Selección de subconjuntos\n",
    "Aquí vamos a implementar los métodos que reducen el número de parámetros en un modelo restringuiendo el modelo a un subconjunto de los predictores. \n",
    "### Selección del mejor subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "47e124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mejor_subconjunto(X, y, criterio='AIC', X_val=None, y_val=None, k_cv=5, verbose=True):\n",
    "    # p es el número de características (predictores) en el conjunto de datos\n",
    "    p = X.shape[1]\n",
    "    n = len(y)  # n es el número de observaciones\n",
    "    predictores = X.columns  # Obtiene los nombres de las características (columnas de X)\n",
    "    resultados_por_k = []  # Lista para almacenar los resultados de cada k\n",
    "\n",
    "    # Para Cp: modelo completo\n",
    "    X_full = add_constant(X)  # Agrega la constante (intercepto)\n",
    "    modelo_full = OLS(y, X_full).fit()  # Ajusta el modelo completo usando OLS\n",
    "    sigma2_hat = modelo_full.scale  # Estima sigma^2, el error cuadrático medio\n",
    "\n",
    "    # Modelo nulo (sin predictores)\n",
    "    modelo_nulo = OLS(y, np.ones((n, 1))).fit()  # Modelo que predice la media de y\n",
    "    resultados_por_k.append({\n",
    "        'k': 0,  # Modelo nulo tiene 0 predictores\n",
    "        'modelo': modelo_nulo,\n",
    "        'predictores': []\n",
    "    })\n",
    "\n",
    "    # Iterar sobre diferentes valores de k (número de predictores)\n",
    "    for k in range(1, p + 1):\n",
    "        mejor_r2 = -np.inf  # Inicializa el mejor R² en un valor muy negativo\n",
    "        mejor_modelo_k = None  # Inicializa el mejor modelo\n",
    "        mejor_comb = None  # Inicializa la mejor combinación de predictores\n",
    "\n",
    "        # Genera todas las combinaciones posibles de k predictores\n",
    "        for subset in combinations(predictores, k):\n",
    "            X_k = add_constant(X[list(subset)])  # Agrega la constante a la combinación de predictores\n",
    "            modelo = OLS(y, X_k).fit()  # Ajusta el modelo OLS con estos predictores\n",
    "            r2 = modelo.rsquared  # Obtiene el R² del modelo\n",
    "\n",
    "            # Si el R² es mejor que el anterior, actualiza los resultados\n",
    "            if r2 > mejor_r2:\n",
    "                mejor_r2 = r2\n",
    "                mejor_modelo_k = modelo\n",
    "                mejor_comb = subset\n",
    "\n",
    "        # Almacena los resultados de este k en la lista\n",
    "        resultados_por_k.append({\n",
    "            'k': k,  # Número de predictores\n",
    "            'modelo': mejor_modelo_k,  # Mejor modelo encontrado\n",
    "            'predictores': mejor_comb,  # Mejor combinación de predictores\n",
    "        })\n",
    "\n",
    "    metricas = []  # Lista para almacenar las métricas de cada modelo\n",
    "    mejores_modelos_cv = []  # Lista para almacenar los mejores modelos según validación cruzada\n",
    "\n",
    "    # Calcula las métricas de cada modelo dependiendo del criterio elegido\n",
    "    for res in resultados_por_k:\n",
    "        modelo = res['modelo']\n",
    "\n",
    "        # Selección según el criterio Cp\n",
    "        if criterio == 'Cp':\n",
    "            k = res['k']\n",
    "            rss = np.sum(modelo.resid ** 2)  # Residual sum of squares (RSS)\n",
    "            cp = (rss + 2 * k * sigma2_hat) / n  # Calcula Cp\n",
    "            metricas.append(cp)\n",
    "\n",
    "        # Selección según AIC\n",
    "        elif criterio == 'AIC':\n",
    "            metricas.append(modelo.aic)  # AIC del modelo ajustado\n",
    "\n",
    "        # Selección según BIC\n",
    "        elif criterio == 'BIC':\n",
    "            metricas.append(modelo.bic)  # BIC del modelo ajustado\n",
    "\n",
    "        # Selección según R² ajustado\n",
    "        elif criterio == 'R2_adj':\n",
    "            metricas.append(-modelo.rsquared_adj)  # R² ajustado (negado para minimización)\n",
    "\n",
    "        # Selección según validación\n",
    "        elif criterio == 'validacion':\n",
    "            if X_val is None or y_val is None:\n",
    "                raise ValueError(\"Debes proporcionar X_val e y_val para validación.\")  # Validación debe tener datos\n",
    "            X_val_red = add_constant(X_val[list(res['predictores'])])  # Datos de validación con los predictores seleccionados\n",
    "            y_val_pred = modelo.predict(X_val_red)  # Predicciones en los datos de validación\n",
    "            mse_val = mean_squared_error(y_val, y_val_pred)  # Error cuadrático medio (MSE) en validación\n",
    "            metricas.append(mse_val)\n",
    "\n",
    "        # Selección según validación cruzada\n",
    "        elif criterio == 'cv':\n",
    "            kf = KFold(n_splits=k_cv, shuffle=True, random_state=100)  # Dividir en k pliegues\n",
    "            best_mse_k = float('inf')  # Inicializa el mejor MSE como infinito\n",
    "            best_model_k = None  # Inicializa el mejor modelo\n",
    "\n",
    "            # Realiza la validación cruzada\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                X_train_k, X_val_k = X.iloc[train_idx], X.iloc[val_idx]  # Divide en entrenamiento y validación\n",
    "                y_train_k, y_val_k = y[train_idx], y[val_idx]  # Divide las etiquetas\n",
    "                X_train_red = add_constant(X_train_k[list(res['predictores'])])  # Datos de entrenamiento con predictores seleccionados\n",
    "                modelo_k = OLS(y_train_k, X_train_red).fit()  # Ajusta el modelo en el conjunto de entrenamiento\n",
    "                X_val_red = add_constant(X_val_k[list(res['predictores'])])  # Datos de validación\n",
    "                y_pred_k = modelo_k.predict(X_val_red)  # Predicciones en validación\n",
    "                mse_k = mean_squared_error(y_val_k, y_pred_k)  # Calcula el MSE\n",
    "\n",
    "                # Si el MSE es mejor, actualiza el mejor modelo\n",
    "                if mse_k < best_mse_k:\n",
    "                    best_mse_k = mse_k\n",
    "                    best_model_k = modelo_k\n",
    "\n",
    "            # Almacena el mejor modelo encontrado en la validación cruzada\n",
    "            metricas.append(best_mse_k)\n",
    "            mejores_modelos_cv.append({\n",
    "                'modelo': best_model_k,  # Mejor modelo encontrado\n",
    "                'mse': best_mse_k,  # Mejor MSE\n",
    "                'predictores': res['predictores']  # Combinación de predictores\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Criterio no reconocido.\")  # Si el criterio no es reconocido\n",
    "\n",
    "    # Selecciona el modelo con la mejor métrica\n",
    "    idx_mejor = int(np.argmin(metricas))  # Encuentra el índice del mejor modelo (mínimo de las métricas)\n",
    "    mejor_modelo = resultados_por_k[idx_mejor]  # Obtiene el mejor modelo\n",
    "\n",
    "    # Si el criterio es validación cruzada, devuelve el mejor modelo y su MSE\n",
    "    if criterio == 'cv':\n",
    "        mejor_modelo_cv = mejores_modelos_cv[idx_mejor]\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Mejor modelo según CV ===\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Mejor MSE en CV: {mejor_modelo_cv['mse']:.4f}\")  # MSE del mejor modelo\n",
    "            print(mejor_modelo_cv['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo_cv, mejor_modelo_cv['mse']  # Devuelve el mejor modelo y su MSE\n",
    "\n",
    "    # Si el criterio no es validación cruzada, devuelve el mejor modelo según el criterio seleccionado\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"\\n========= Mejor modelo según {criterio} =========\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Métrica ({criterio}): {metricas[idx_mejor]:.4f}\")  # Métrica del mejor modelo\n",
    "            print(mejor_modelo['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo, metricas[idx_mejor]  # Devuelve el mejor modelo y su métrica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "dca833a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según Cp =========\n",
      "  k = 6\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's1', 's4', 's5')\n",
      "  Métrica (Cp): 3017.2779\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     50.93\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           4.70e-43\n",
      "Time:                        18:21:13   Log-Likelihood:                -1664.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     301   BIC:                             3370.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1199      3.117     47.844      0.000     142.986     155.253\n",
      "sex         -194.3866     72.630     -2.676      0.008    -337.313     -51.460\n",
      "bmi          552.6452     77.896      7.095      0.000     399.355     705.935\n",
      "bp           311.5953     75.813      4.110      0.000     162.404     460.787\n",
      "s1          -265.5925     85.323     -3.113      0.002    -433.498     -97.687\n",
      "s4           304.6737     94.831      3.213      0.001     118.058     491.289\n",
      "s5           535.1234     90.629      5.905      0.000     356.777     713.470\n",
      "==============================================================================\n",
      "Omnibus:                        5.500   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.183   Prob(JB):                        0.115\n",
      "Kurtosis:                       2.549   Cond. No.                         37.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar Cp:\n",
    "modelo_cp, valor_cp = mejor_subconjunto(X_train, y_train, criterio='Cp', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "65173c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según AIC =========\n",
      "  k = 6\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's1', 's4', 's5')\n",
      "  Métrica (AIC): 3343.7095\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     50.93\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           4.70e-43\n",
      "Time:                        18:21:16   Log-Likelihood:                -1664.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     301   BIC:                             3370.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1199      3.117     47.844      0.000     142.986     155.253\n",
      "sex         -194.3866     72.630     -2.676      0.008    -337.313     -51.460\n",
      "bmi          552.6452     77.896      7.095      0.000     399.355     705.935\n",
      "bp           311.5953     75.813      4.110      0.000     162.404     460.787\n",
      "s1          -265.5925     85.323     -3.113      0.002    -433.498     -97.687\n",
      "s4           304.6737     94.831      3.213      0.001     118.058     491.289\n",
      "s5           535.1234     90.629      5.905      0.000     356.777     713.470\n",
      "==============================================================================\n",
      "Omnibus:                        5.500   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.183   Prob(JB):                        0.115\n",
      "Kurtosis:                       2.549   Cond. No.                         37.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar AIC:\n",
    "modelo_aic, valor_aic = mejor_subconjunto(X_train, y_train, criterio='AIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "712db767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según BIC =========\n",
      "  k = 5\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's3', 's5')\n",
      "  Métrica (BIC): 3366.2221\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.500\n",
      "Model:                            OLS   Adj. R-squared:                  0.492\n",
      "Method:                 Least Squares   F-statistic:                     60.48\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.60e-43\n",
      "Time:                        18:21:20   Log-Likelihood:                -1665.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     302   BIC:                             3366.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1609      3.119     47.820      0.000     143.023     155.299\n",
      "sex         -202.2475     73.306     -2.759      0.006    -346.504     -57.991\n",
      "bmi          533.6485     79.130      6.744      0.000     377.933     689.364\n",
      "bp           302.2724     75.716      3.992      0.000     153.275     451.270\n",
      "s3          -283.2347     77.470     -3.656      0.000    -435.685    -130.785\n",
      "s5           485.5772     75.733      6.412      0.000     336.545     634.609\n",
      "==============================================================================\n",
      "Omnibus:                        5.841   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.054   Jarque-Bera (JB):                4.294\n",
      "Skew:                           0.162   Prob(JB):                        0.117\n",
      "Kurtosis:                       2.520   Cond. No.                         32.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar BIC:\n",
    "modelo_bic, valor_bic = mejor_subconjunto(X_train, y_train, criterio='BIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "08eaa8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según R2_adj =========\n",
      "  k = 7\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's1', 's2', 's4', 's5')\n",
      "  Métrica (R2_adj): -0.4945\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     43.90\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.81e-42\n",
      "Time:                        18:21:24   Log-Likelihood:                -1664.2\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     300   BIC:                             3374.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2681      3.118     47.879      0.000     143.133     155.403\n",
      "sex         -210.9450     73.979     -2.851      0.005    -356.528     -65.362\n",
      "bmi          530.8222     80.093      6.628      0.000     373.207     688.437\n",
      "bp           312.5216     75.774      4.124      0.000     163.406     461.638\n",
      "s1          -535.9169    248.181     -2.159      0.032   -1024.314     -47.520\n",
      "s2           307.8250    265.404      1.160      0.247    -214.465     830.115\n",
      "s4           186.1348    139.385      1.335      0.183     -88.161     460.430\n",
      "s5           658.5669    139.757      4.712      0.000     383.539     933.595\n",
      "==============================================================================\n",
      "Omnibus:                        5.118   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.077   Jarque-Bera (JB):                3.867\n",
      "Skew:                           0.151   Prob(JB):                        0.145\n",
      "Kurtosis:                       2.542   Cond. No.                         126.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar R2_adj:\n",
    "modelo_R2_adj, valor_R2_adj = mejor_subconjunto(X_train, y_train, criterio='R2_adj', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "5e9c778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según validacion =========\n",
      "  k = 7\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's1', 's2', 's4', 's5')\n",
      "  Métrica (validacion): 3062.6161\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     43.90\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.81e-42\n",
      "Time:                        18:21:28   Log-Likelihood:                -1664.2\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     300   BIC:                             3374.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2681      3.118     47.879      0.000     143.133     155.403\n",
      "sex         -210.9450     73.979     -2.851      0.005    -356.528     -65.362\n",
      "bmi          530.8222     80.093      6.628      0.000     373.207     688.437\n",
      "bp           312.5216     75.774      4.124      0.000     163.406     461.638\n",
      "s1          -535.9169    248.181     -2.159      0.032   -1024.314     -47.520\n",
      "s2           307.8250    265.404      1.160      0.247    -214.465     830.115\n",
      "s4           186.1348    139.385      1.335      0.183     -88.161     460.430\n",
      "s5           658.5669    139.757      4.712      0.000     383.539     933.595\n",
      "==============================================================================\n",
      "Omnibus:                        5.118   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.077   Jarque-Bera (JB):                3.867\n",
      "Skew:                           0.151   Prob(JB):                        0.145\n",
      "Kurtosis:                       2.542   Cond. No.                         126.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación (debe tener los datos de validación):\n",
    "modelo_val, mse_val = mejor_subconjunto(X_train, y_train, criterio='validacion', X_val=X_val, y_val=y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a90482b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mejor modelo según CV ===\n",
      "  k = 5\n",
      "  Predictores: ('sex', 'bmi', 'bp', 's3', 's5')\n",
      "  Mejor MSE en CV: 2592.9503\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.488\n",
      "Model:                            OLS   Adj. R-squared:                  0.479\n",
      "Method:                 Least Squares   F-statistic:                     59.19\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           3.56e-43\n",
      "Time:                        18:21:32   Log-Likelihood:                -1721.2\n",
      "No. Observations:                 317   AIC:                             3454.\n",
      "Df Residuals:                     311   BIC:                             3477.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.9698      3.132     47.878      0.000     143.807     156.133\n",
      "sex         -222.0977     72.194     -3.076      0.002    -364.148     -80.047\n",
      "bmi          529.2029     76.802      6.891      0.000     378.086     680.320\n",
      "bp           270.2858     77.443      3.490      0.001     117.906     422.665\n",
      "s3          -254.7898     80.931     -3.148      0.002    -414.031     -95.549\n",
      "s5           501.4228     79.415      6.314      0.000     345.164     657.681\n",
      "==============================================================================\n",
      "Omnibus:                        2.397   Durbin-Watson:                   2.092\n",
      "Prob(Omnibus):                  0.302   Jarque-Bera (JB):                2.039\n",
      "Skew:                           0.079   Prob(JB):                        0.361\n",
      "Kurtosis:                       2.640   Cond. No.                         32.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación cruzada con k=5:\n",
    "modelo_cv, mse_cv = mejor_subconjunto(pd.concat([X_train, X_val], axis=0), np.concatenate([y_train, y_val]), criterio='cv', k_cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d4fb8",
   "metadata": {},
   "source": [
    "### Selección Paso a Paso hacia Adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "b60f53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccion_paso_a_paso_adelante(X, y, criterio='AIC', X_val=None, y_val=None, k_cv=5, verbose=True):\n",
    "\n",
    "    p = X.shape[1]  # Número de predictores\n",
    "    n = len(y)  # Número de observaciones\n",
    "    predictores = X.columns  # Nombres de las columnas de X\n",
    "    predictores_restantes = set(predictores)  # Inicializa un conjunto con todos los predictores\n",
    "    resultados_por_k = []  # Almacena los modelos seleccionados en cada paso\n",
    "\n",
    "    # Para Cp: modelo completo\n",
    "    X_full = add_constant(X)  # Agrega la constante (intercepto)\n",
    "    modelo_full = OLS(y, X_full).fit()  # Ajusta el modelo completo usando OLS\n",
    "    sigma2_hat = modelo_full.scale  # Estima sigma^2, el error cuadrático medio\n",
    "\n",
    "    # Modelo nulo (sin predictores)\n",
    "    modelo_nulo = OLS(y, np.ones((n, 1))).fit()  # Modelo que predice la media de y\n",
    "    resultados_por_k.append({\n",
    "        'k': 0,  # El modelo nulo tiene 0 predictores\n",
    "        'modelo': modelo_nulo,\n",
    "        'predictores': []\n",
    "    })\n",
    "\n",
    "    # Iterar sobre el número de predictores, desde 1 hasta p\n",
    "    for k in range(1, p + 1):\n",
    "        mejor_r2 = -np.inf  # Inicializa el mejor R² en un valor muy negativo\n",
    "        mejor_modelo_k = None  # Inicializa el mejor modelo\n",
    "        mejor_predictores = None  # Inicializa la mejor combinación de predictores\n",
    "        predictores_a_agregar = []  # Lista de predictores a agregar en cada paso\n",
    "        \n",
    "        # Evaluar todos los modelos que agregan un predictor adicional\n",
    "        for predictor in predictores_restantes:\n",
    "            predictores_a_probar = list(resultados_por_k[k-1]['predictores']) + [predictor]\n",
    "            X_k = add_constant(X[predictores_a_probar])  # Agregar la constante\n",
    "            modelo = OLS(y, X_k).fit()  # Ajusta el modelo OLS\n",
    "            r2 = modelo.rsquared  # Obtiene el R² del modelo\n",
    "            \n",
    "            # Si el R² es mejor que el anterior, actualiza los resultados\n",
    "            if r2 > mejor_r2:\n",
    "                mejor_r2 = r2\n",
    "                mejor_modelo_k = modelo\n",
    "                mejor_predictores = predictores_a_probar\n",
    "                predictor_a_agregar = predictor\n",
    "\n",
    "        # Después de elegir el mejor predictor, eliminarlo de los predictores restantes\n",
    "        predictores_restantes.remove(predictor_a_agregar)\n",
    "\n",
    "        # Almacena los resultados del paso k\n",
    "        resultados_por_k.append({\n",
    "            'k': k,\n",
    "            'modelo': mejor_modelo_k,\n",
    "            'predictores': mejor_predictores,\n",
    "        })\n",
    "\n",
    "    # Inicializa las métricas para comparar modelos\n",
    "    metricas = []\n",
    "    mejores_modelos_cv = []\n",
    "\n",
    "    # Calcula las métricas de cada modelo dependiendo del criterio elegido\n",
    "    for res in resultados_por_k:\n",
    "        modelo = res['modelo']\n",
    "\n",
    "        # Selección según Cp\n",
    "        if criterio == 'Cp':\n",
    "            k = res['k']\n",
    "            rss = np.sum(modelo.resid ** 2)  # Residual sum of squares (RSS)\n",
    "            cp = (rss + 2 * k * sigma2_hat) / n  # Calcula Cp\n",
    "            metricas.append(cp)\n",
    "\n",
    "        # Selección según AIC\n",
    "        elif criterio == 'AIC':\n",
    "            metricas.append(modelo.aic)  # AIC del modelo ajustado\n",
    "\n",
    "        # Selección según BIC\n",
    "        elif criterio == 'BIC':\n",
    "            metricas.append(modelo.bic)  # BIC del modelo ajustado\n",
    "\n",
    "        # Selección según R² ajustado\n",
    "        elif criterio == 'R2_adj':\n",
    "            metricas.append(-modelo.rsquared_adj)  # R² ajustado (negado para minimización)\n",
    "\n",
    "        # Selección según validación\n",
    "        elif criterio == 'validacion':\n",
    "            if X_val is None or y_val is None:\n",
    "                raise ValueError(\"Debes proporcionar X_val e y_val para validación.\")  # Validación debe tener datos\n",
    "            X_val_red = add_constant(X_val[list(res['predictores'])])  # Datos de validación con los predictores seleccionados\n",
    "            y_val_pred = modelo.predict(X_val_red)  # Predicciones en los datos de validación\n",
    "            mse_val = mean_squared_error(y_val, y_val_pred)  # Error cuadrático medio (MSE) en validación\n",
    "            metricas.append(mse_val)\n",
    "\n",
    "        # Selección según validación cruzada\n",
    "        elif criterio == 'cv':\n",
    "            kf = KFold(n_splits=k_cv, shuffle=True, random_state=100)  # Dividir en k pliegues\n",
    "            best_mse_k = float('inf')  # Inicializa el mejor MSE como infinito\n",
    "            best_model_k = None  # Inicializa el mejor modelo\n",
    "\n",
    "            # Realiza la validación cruzada\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                X_train_k, X_val_k = X.iloc[train_idx], X.iloc[val_idx]  # Divide en entrenamiento y validación\n",
    "                y_train_k, y_val_k = y[train_idx], y[val_idx]  # Divide las etiquetas\n",
    "                X_train_red = add_constant(X_train_k[list(res['predictores'])])  # Datos de entrenamiento con predictores seleccionados\n",
    "                modelo_k = OLS(y_train_k, X_train_red).fit()  # Ajusta el modelo en el conjunto de entrenamiento\n",
    "                X_val_red = add_constant(X_val_k[list(res['predictores'])])  # Datos de validación\n",
    "                y_pred_k = modelo_k.predict(X_val_red)  # Predicciones en validación\n",
    "                mse_k = mean_squared_error(y_val_k, y_pred_k)  # Calcula el MSE\n",
    "\n",
    "                # Si el MSE es mejor, actualiza el mejor modelo\n",
    "                if mse_k < best_mse_k:\n",
    "                    best_mse_k = mse_k\n",
    "                    best_model_k = modelo_k\n",
    "\n",
    "            # Almacena el mejor modelo encontrado en la validación cruzada\n",
    "            metricas.append(best_mse_k)\n",
    "            mejores_modelos_cv.append({\n",
    "                'modelo': best_model_k,  # Mejor modelo encontrado\n",
    "                'mse': best_mse_k,  # Mejor MSE\n",
    "                'predictores': res['predictores']  # Combinación de predictores\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Criterio no reconocido.\")  # Si el criterio no es reconocido\n",
    "\n",
    "    # Selecciona el modelo con la mejor métrica\n",
    "    idx_mejor = int(np.argmin(metricas))  # Encuentra el índice del mejor modelo (mínimo de las métricas)\n",
    "    mejor_modelo = resultados_por_k[idx_mejor]  # Obtiene el mejor modelo\n",
    "\n",
    "    # Si el criterio es validación cruzada, devuelve el mejor modelo y su MSE\n",
    "    if criterio == 'cv':\n",
    "        mejor_modelo_cv = mejores_modelos_cv[idx_mejor]\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Mejor modelo según CV ===\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Mejor MSE en CV: {mejor_modelo_cv['mse']:.4f}\")  # MSE del mejor modelo\n",
    "            print(mejor_modelo_cv['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo_cv, mejor_modelo_cv['mse']  # Devuelve el mejor modelo y su MSE\n",
    "\n",
    "    # Si el criterio no es validación cruzada, devuelve el mejor modelo según el criterio seleccionado\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"\\n========= Mejor modelo según {criterio} =========\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Métrica ({criterio}): {metricas[idx_mejor]:.4f}\")  # Métrica del mejor modelo\n",
    "            print(mejor_modelo['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo, metricas[idx_mejor]  # Devuelve el mejor modelo y su métrica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "2eb4220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según Cp =========\n",
      "  k = 5\n",
      "  Predictores: ['bmi', 's5', 'bp', 's3', 'sex']\n",
      "  Métrica (Cp): 3018.0770\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.500\n",
      "Model:                            OLS   Adj. R-squared:                  0.492\n",
      "Method:                 Least Squares   F-statistic:                     60.48\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.60e-43\n",
      "Time:                        18:21:32   Log-Likelihood:                -1665.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     302   BIC:                             3366.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1609      3.119     47.820      0.000     143.023     155.299\n",
      "bmi          533.6485     79.130      6.744      0.000     377.933     689.364\n",
      "s5           485.5772     75.733      6.412      0.000     336.545     634.609\n",
      "bp           302.2724     75.716      3.992      0.000     153.275     451.270\n",
      "s3          -283.2347     77.470     -3.656      0.000    -435.685    -130.785\n",
      "sex         -202.2475     73.306     -2.759      0.006    -346.504     -57.991\n",
      "==============================================================================\n",
      "Omnibus:                        5.841   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.054   Jarque-Bera (JB):                4.294\n",
      "Skew:                           0.162   Prob(JB):                        0.117\n",
      "Kurtosis:                       2.520   Cond. No.                         32.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar Cp:\n",
    "modelo_forward_cp, valor_forward_cp = seleccion_paso_a_paso_adelante(X_train, y_train, criterio='Cp', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "f112dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según AIC =========\n",
      "  k = 5\n",
      "  Predictores: ['bmi', 's5', 'bp', 's3', 'sex']\n",
      "  Métrica (AIC): 3343.8415\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.500\n",
      "Model:                            OLS   Adj. R-squared:                  0.492\n",
      "Method:                 Least Squares   F-statistic:                     60.48\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.60e-43\n",
      "Time:                        18:21:32   Log-Likelihood:                -1665.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     302   BIC:                             3366.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1609      3.119     47.820      0.000     143.023     155.299\n",
      "bmi          533.6485     79.130      6.744      0.000     377.933     689.364\n",
      "s5           485.5772     75.733      6.412      0.000     336.545     634.609\n",
      "bp           302.2724     75.716      3.992      0.000     153.275     451.270\n",
      "s3          -283.2347     77.470     -3.656      0.000    -435.685    -130.785\n",
      "sex         -202.2475     73.306     -2.759      0.006    -346.504     -57.991\n",
      "==============================================================================\n",
      "Omnibus:                        5.841   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.054   Jarque-Bera (JB):                4.294\n",
      "Skew:                           0.162   Prob(JB):                        0.117\n",
      "Kurtosis:                       2.520   Cond. No.                         32.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar AIC:\n",
    "modelo_forward_aic, valor_forward_aic = seleccion_paso_a_paso_adelante(X_train, y_train, criterio='AIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "3ddcacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según BIC =========\n",
      "  k = 5\n",
      "  Predictores: ['bmi', 's5', 'bp', 's3', 'sex']\n",
      "  Métrica (BIC): 3366.2221\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.500\n",
      "Model:                            OLS   Adj. R-squared:                  0.492\n",
      "Method:                 Least Squares   F-statistic:                     60.48\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.60e-43\n",
      "Time:                        18:21:33   Log-Likelihood:                -1665.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     302   BIC:                             3366.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1609      3.119     47.820      0.000     143.023     155.299\n",
      "bmi          533.6485     79.130      6.744      0.000     377.933     689.364\n",
      "s5           485.5772     75.733      6.412      0.000     336.545     634.609\n",
      "bp           302.2724     75.716      3.992      0.000     153.275     451.270\n",
      "s3          -283.2347     77.470     -3.656      0.000    -435.685    -130.785\n",
      "sex         -202.2475     73.306     -2.759      0.006    -346.504     -57.991\n",
      "==============================================================================\n",
      "Omnibus:                        5.841   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.054   Jarque-Bera (JB):                4.294\n",
      "Skew:                           0.162   Prob(JB):                        0.117\n",
      "Kurtosis:                       2.520   Cond. No.                         32.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar BIC:\n",
    "modelo_forward_bic, valor_forward_bic = seleccion_paso_a_paso_adelante(X_train, y_train, criterio='BIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "72ffbda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según R2_adj =========\n",
      "  k = 8\n",
      "  Predictores: ['bmi', 's5', 'bp', 's3', 'sex', 's1', 's4', 's2']\n",
      "  Métrica (R2_adj): -0.4933\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.493\n",
      "Method:                 Least Squares   F-statistic:                     38.35\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.09e-41\n",
      "Time:                        18:21:33   Log-Likelihood:                -1664.0\n",
      "No. Observations:                 308   AIC:                             3346.\n",
      "Df Residuals:                     299   BIC:                             3380.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2696      3.121     47.822      0.000     143.127     155.412\n",
      "bmi          531.8545     80.212      6.631      0.000     374.003     689.706\n",
      "s5           734.1628    199.145      3.687      0.000     342.259    1126.066\n",
      "bp           313.3133     75.879      4.129      0.000     163.989     462.638\n",
      "s3           132.8862    249.094      0.533      0.594    -357.314     623.087\n",
      "sex         -210.3590     74.075     -2.840      0.005    -356.134     -64.584\n",
      "s1          -764.1118    494.683     -1.545      0.123   -1737.613     209.390\n",
      "s4           254.2544    189.154      1.344      0.180    -117.987     626.496\n",
      "s2           469.1851    402.610      1.165      0.245    -323.123    1261.494\n",
      "==============================================================================\n",
      "Omnibus:                        5.166   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.076   Jarque-Bera (JB):                3.918\n",
      "Skew:                           0.155   Prob(JB):                        0.141\n",
      "Kurtosis:                       2.542   Cond. No.                         223.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar R2_adj:\n",
    "modelo_forward_r2_adj, valor_forward_r2_adj = seleccion_paso_a_paso_adelante(X_train, y_train, criterio='R2_adj', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "a470f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según validacion =========\n",
      "  k = 6\n",
      "  Predictores: ['bmi', 's5', 'bp', 's3', 'sex', 's1']\n",
      "  Métrica (validacion): 3036.5921\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.502\n",
      "Model:                            OLS   Adj. R-squared:                  0.492\n",
      "Method:                 Least Squares   F-statistic:                     50.55\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           8.21e-43\n",
      "Time:                        18:21:33   Log-Likelihood:                -1665.4\n",
      "No. Observations:                 308   AIC:                             3345.\n",
      "Df Residuals:                     301   BIC:                             3371.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2918      3.122     47.814      0.000     143.147     155.436\n",
      "bmi          541.0733     79.499      6.806      0.000     384.629     697.518\n",
      "s5           535.8737     91.562      5.853      0.000     355.691     716.056\n",
      "bp           306.3263     75.835      4.039      0.000     157.092     455.560\n",
      "s3          -252.7338     83.523     -3.026      0.003    -417.096     -88.372\n",
      "sex         -196.1180     73.580     -2.665      0.008    -340.913     -51.323\n",
      "s1           -86.1929     88.171     -0.978      0.329    -259.702      87.316\n",
      "==============================================================================\n",
      "Omnibus:                        4.591   Durbin-Watson:                   1.927\n",
      "Prob(Omnibus):                  0.101   Jarque-Bera (JB):                3.603\n",
      "Skew:                           0.151   Prob(JB):                        0.165\n",
      "Kurtosis:                       2.564   Cond. No.                         40.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación (debe tener los datos de validación):\n",
    "modelo_forward_val, mse_forward_val = seleccion_paso_a_paso_adelante(X_train, y_train, criterio='validacion', X_val=X_val, y_val=y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "30e04485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mejor modelo según CV ===\n",
      "  k = 8\n",
      "  Predictores: ['bmi', 's5', 'bp', 's1', 'sex', 's2', 's4', 's6']\n",
      "  Mejor MSE en CV: 2639.5306\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.497\n",
      "Model:                            OLS   Adj. R-squared:                  0.484\n",
      "Method:                 Least Squares   F-statistic:                     38.03\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           8.96e-42\n",
      "Time:                        18:21:34   Log-Likelihood:                -1718.3\n",
      "No. Observations:                 317   AIC:                             3455.\n",
      "Df Residuals:                     308   BIC:                             3488.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        150.1885      3.122     48.113      0.000     144.046     156.331\n",
      "bmi          532.6945     78.526      6.784      0.000     378.179     687.210\n",
      "s5           705.3575    145.402      4.851      0.000     419.251     991.464\n",
      "bp           266.6735     78.859      3.382      0.001     111.504     421.843\n",
      "s1          -552.3222    246.717     -2.239      0.026   -1037.787     -66.857\n",
      "sex         -221.5334     73.247     -3.024      0.003    -365.660     -77.406\n",
      "s2           295.4498    263.310      1.122      0.263    -222.664     813.564\n",
      "s4           108.3904    141.915      0.764      0.446    -170.855     387.636\n",
      "s6            49.7172     79.081      0.629      0.530    -105.891     205.325\n",
      "==============================================================================\n",
      "Omnibus:                        1.383   Durbin-Watson:                   2.102\n",
      "Prob(Omnibus):                  0.501   Jarque-Bera (JB):                1.307\n",
      "Skew:                           0.038   Prob(JB):                        0.520\n",
      "Kurtosis:                       2.695   Cond. No.                         125.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación cruzada con k=5:\n",
    "modelo_forward_cv, mse_forward_cv = seleccion_paso_a_paso_adelante(pd.concat([X_train, X_val], axis=0), np.concatenate([y_train, y_val]), criterio='cv', k_cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b806aa",
   "metadata": {},
   "source": [
    "### Selección Paso a Paso hacia Atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "3050c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccion_paso_a_paso_atras(X, y, criterio='AIC', X_val=None, y_val=None, k_cv=5, verbose=True):\n",
    "\n",
    "    p = X.shape[1]  # Número de predictores\n",
    "    n = len(y)  # Número de observaciones\n",
    "    predictores = X.columns  # Nombres de las columnas de X\n",
    "    predictores_seleccionados = set(predictores)  # Inicializa un conjunto con todos los predictores\n",
    "    resultados_por_k = []  # Almacena los modelos seleccionados en cada paso\n",
    "\n",
    "    # Para Cp: modelo completo\n",
    "    X_full = add_constant(X)  # Agrega la constante (intercepto)\n",
    "    modelo_full = OLS(y, X_full).fit()  # Ajusta el modelo completo usando OLS\n",
    "    sigma2_hat = modelo_full.scale\n",
    "\n",
    "    # Modelo completo (con todos los predictores)\n",
    "    X_completo = sm.add_constant(X)  # Agregar la constante\n",
    "    modelo_completo = sm.OLS(y, X_completo).fit()\n",
    "    resultados_por_k.append({\n",
    "        'k': p,  # El modelo completo tiene p predictores\n",
    "        'modelo': modelo_completo,\n",
    "        'predictores': predictores.tolist()\n",
    "    })\n",
    "\n",
    "    # Iterar desde el número de predictores p hasta 1\n",
    "    for k in range(p, 0, -1):\n",
    "        mejor_r2 = -np.inf  # Inicializa el mejor R² en un valor muy negativo\n",
    "        mejor_modelo_k = None  # Inicializa el mejor modelo\n",
    "        mejor_predictores = None  # Inicializa la mejor combinación de predictores\n",
    "        predictores_a_eliminar = None  # Predictor a eliminar en cada paso\n",
    "        \n",
    "        # Evaluar todos los modelos que eliminan un predictor\n",
    "        for predictor in predictores_seleccionados:\n",
    "            predictores_a_probar = list(resultados_por_k[p - k]['predictores'])\n",
    "            predictores_a_probar.remove(predictor)\n",
    "            X_k = sm.add_constant(X[predictores_a_probar])  # Agregar la constante\n",
    "            modelo = sm.OLS(y, X_k).fit()  # Ajusta el modelo OLS\n",
    "            r2 = modelo.rsquared  # Obtiene el R² del modelo\n",
    "            \n",
    "            # Si el R² es mejor que el anterior, actualiza los resultados\n",
    "            if r2 > mejor_r2:\n",
    "                mejor_r2 = r2\n",
    "                mejor_modelo_k = modelo\n",
    "                mejor_predictores = predictores_a_probar\n",
    "                predictores_a_eliminar = predictor  # Corregir aquí: asignamos a la variable correcta\n",
    "\n",
    "        # Después de elegir el mejor predictor, eliminarlo de los predictores seleccionados\n",
    "        predictores_seleccionados.remove(predictores_a_eliminar)  # Usar la variable correcta\n",
    "\n",
    "        # Almacena los resultados del paso k\n",
    "        resultados_por_k.append({\n",
    "            'k': k - 1,\n",
    "            'modelo': mejor_modelo_k,\n",
    "            'predictores': mejor_predictores,\n",
    "        })\n",
    "\n",
    "    # Inicializa las métricas para comparar modelos\n",
    "    metricas = []\n",
    "    mejores_modelos_cv = []\n",
    "\n",
    "    # Calcula las métricas de cada modelo dependiendo del criterio elegido\n",
    "    for res in resultados_por_k:\n",
    "        modelo = res['modelo']\n",
    "\n",
    "        # Selección según Cp\n",
    "        if criterio == 'Cp':\n",
    "            k = res['k']\n",
    "            rss = np.sum(modelo.resid ** 2)  # Residual sum of squares (RSS)\n",
    "            cp = (rss + 2 * k * sigma2_hat) / n  # Calcula Cp\n",
    "            metricas.append(cp)\n",
    "\n",
    "        # Selección según AIC\n",
    "        elif criterio == 'AIC':\n",
    "            metricas.append(modelo.aic)  # AIC del modelo ajustado\n",
    "\n",
    "        # Selección según BIC\n",
    "        elif criterio == 'BIC':\n",
    "            metricas.append(modelo.bic)  # BIC del modelo ajustado\n",
    "\n",
    "        # Selección según R² ajustado\n",
    "        elif criterio == 'R2_adj':\n",
    "            metricas.append(-modelo.rsquared_adj)  # R² ajustado (negado para minimización)\n",
    "\n",
    "        # Selección según validación\n",
    "        elif criterio == 'validacion':\n",
    "            if X_val is None or y_val is None:\n",
    "                raise ValueError(\"Debes proporcionar X_val e y_val para validación.\")  # Validación debe tener datos\n",
    "            X_val_red = sm.add_constant(X_val[list(res['predictores'])])  # Datos de validación con los predictores seleccionados\n",
    "            y_val_pred = modelo.predict(X_val_red)  # Predicciones en los datos de validación\n",
    "            mse_val = mean_squared_error(y_val, y_val_pred)  # Error cuadrático medio (MSE) en validación\n",
    "            metricas.append(mse_val)\n",
    "\n",
    "        # Selección según validación cruzada\n",
    "        elif criterio == 'cv':\n",
    "            kf = KFold(n_splits=k_cv, shuffle=True, random_state=100)  # Dividir en k pliegues\n",
    "            best_mse_k = float('inf')  # Inicializa el mejor MSE como infinito\n",
    "            best_model_k = None  # Inicializa el mejor modelo\n",
    "\n",
    "            # Realiza la validación cruzada\n",
    "            for train_idx, val_idx in kf.split(X):\n",
    "                X_train_k, X_val_k = X.iloc[train_idx], X.iloc[val_idx]  # Divide en entrenamiento y validación\n",
    "                y_train_k, y_val_k = y[train_idx], y[val_idx]  # Divide las etiquetas\n",
    "                X_train_red = sm.add_constant(X_train_k[list(res['predictores'])])  # Datos de entrenamiento con predictores seleccionados\n",
    "                modelo_k = sm.OLS(y_train_k, X_train_red).fit()  # Ajusta el modelo en el conjunto de entrenamiento\n",
    "                X_val_red = sm.add_constant(X_val_k[list(res['predictores'])])  # Datos de validación\n",
    "                y_pred_k = modelo_k.predict(X_val_red)  # Predicciones en validación\n",
    "                mse_k = mean_squared_error(y_val_k, y_pred_k)  # Calcula el MSE\n",
    "\n",
    "                # Si el MSE es mejor, actualiza el mejor modelo\n",
    "                if mse_k < best_mse_k:\n",
    "                    best_mse_k = mse_k\n",
    "                    best_model_k = modelo_k\n",
    "\n",
    "            # Almacena el mejor modelo encontrado en la validación cruzada\n",
    "            metricas.append(best_mse_k)\n",
    "            mejores_modelos_cv.append({\n",
    "                'modelo': best_model_k,  # Mejor modelo encontrado\n",
    "                'mse': best_mse_k,  # Mejor MSE\n",
    "                'predictores': res['predictores']  # Combinación de predictores\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Criterio no reconocido.\")  # Si el criterio no es reconocido\n",
    "\n",
    "    # Selecciona el modelo con la mejor métrica\n",
    "    idx_mejor = int(np.argmin(metricas))  # Encuentra el índice del mejor modelo (mínimo de las métricas)\n",
    "    mejor_modelo = resultados_por_k[idx_mejor]  # Obtiene el mejor modelo\n",
    "\n",
    "    # Si el criterio es validación cruzada, devuelve el mejor modelo y su MSE\n",
    "    if criterio == 'cv':\n",
    "        mejor_modelo_cv = mejores_modelos_cv[idx_mejor]\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Mejor modelo según CV ===\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Mejor MSE en CV: {mejor_modelo_cv['mse']:.4f}\")  # MSE del mejor modelo\n",
    "            print(mejor_modelo_cv['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo_cv, mejor_modelo_cv['mse']  # Devuelve el mejor modelo y su MSE\n",
    "\n",
    "    # Si el criterio no es validación cruzada, devuelve el mejor modelo según el criterio seleccionado\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"\\n========= Mejor modelo según {criterio} =========\")\n",
    "            print(f\"  k = {mejor_modelo['k']}\")  # Número de predictores\n",
    "            print(f\"  Predictores: {mejor_modelo['predictores']}\")  # Combinación de predictores\n",
    "            print(f\"  Métrica ({criterio}): {metricas[idx_mejor]:.4f}\")  # Métrica del mejor modelo\n",
    "            print(mejor_modelo['modelo'].summary())  # Resumen del modelo\n",
    "        return mejor_modelo, metricas[idx_mejor]  # Devuelve el mejor modelo y su métrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "1cc26cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según Cp =========\n",
      "  k = 6\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's4', 's5']\n",
      "  Métrica (Cp): 3017.2779\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     50.93\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           4.70e-43\n",
      "Time:                        18:21:34   Log-Likelihood:                -1664.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     301   BIC:                             3370.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1199      3.117     47.844      0.000     142.986     155.253\n",
      "sex         -194.3866     72.630     -2.676      0.008    -337.313     -51.460\n",
      "bmi          552.6452     77.896      7.095      0.000     399.355     705.935\n",
      "bp           311.5953     75.813      4.110      0.000     162.404     460.787\n",
      "s1          -265.5925     85.323     -3.113      0.002    -433.498     -97.687\n",
      "s4           304.6737     94.831      3.213      0.001     118.058     491.289\n",
      "s5           535.1234     90.629      5.905      0.000     356.777     713.470\n",
      "==============================================================================\n",
      "Omnibus:                        5.500   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.183   Prob(JB):                        0.115\n",
      "Kurtosis:                       2.549   Cond. No.                         37.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar Cp:\n",
    "modelo_backward_cp, valor_backward_cp = seleccion_paso_a_paso_atras(X_train, y_train, criterio='Cp', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "bf046e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según AIC =========\n",
      "  k = 6\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's4', 's5']\n",
      "  Métrica (AIC): 3343.7095\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     50.93\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           4.70e-43\n",
      "Time:                        18:21:34   Log-Likelihood:                -1664.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     301   BIC:                             3370.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1199      3.117     47.844      0.000     142.986     155.253\n",
      "sex         -194.3866     72.630     -2.676      0.008    -337.313     -51.460\n",
      "bmi          552.6452     77.896      7.095      0.000     399.355     705.935\n",
      "bp           311.5953     75.813      4.110      0.000     162.404     460.787\n",
      "s1          -265.5925     85.323     -3.113      0.002    -433.498     -97.687\n",
      "s4           304.6737     94.831      3.213      0.001     118.058     491.289\n",
      "s5           535.1234     90.629      5.905      0.000     356.777     713.470\n",
      "==============================================================================\n",
      "Omnibus:                        5.500   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.183   Prob(JB):                        0.115\n",
      "Kurtosis:                       2.549   Cond. No.                         37.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar AIC:\n",
    "modelo_backward_aic, valor_backward_aic = seleccion_paso_a_paso_atras(X_train, y_train, criterio='AIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "68854162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según BIC =========\n",
      "  k = 6\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's4', 's5']\n",
      "  Métrica (BIC): 3369.8202\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     50.93\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           4.70e-43\n",
      "Time:                        18:21:35   Log-Likelihood:                -1664.9\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     301   BIC:                             3370.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.1199      3.117     47.844      0.000     142.986     155.253\n",
      "sex         -194.3866     72.630     -2.676      0.008    -337.313     -51.460\n",
      "bmi          552.6452     77.896      7.095      0.000     399.355     705.935\n",
      "bp           311.5953     75.813      4.110      0.000     162.404     460.787\n",
      "s1          -265.5925     85.323     -3.113      0.002    -433.498     -97.687\n",
      "s4           304.6737     94.831      3.213      0.001     118.058     491.289\n",
      "s5           535.1234     90.629      5.905      0.000     356.777     713.470\n",
      "==============================================================================\n",
      "Omnibus:                        5.500   Durbin-Watson:                   1.919\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                4.327\n",
      "Skew:                           0.183   Prob(JB):                        0.115\n",
      "Kurtosis:                       2.549   Cond. No.                         37.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar BIC:\n",
    "modelo_backward_bic, valor_backward_bic = seleccion_paso_a_paso_atras(X_train, y_train, criterio='BIC', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b686da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según R2_adj =========\n",
      "  k = 7\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's2', 's4', 's5']\n",
      "  Métrica (R2_adj): -0.4945\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     43.90\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.81e-42\n",
      "Time:                        18:21:35   Log-Likelihood:                -1664.2\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     300   BIC:                             3374.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2681      3.118     47.879      0.000     143.133     155.403\n",
      "sex         -210.9450     73.979     -2.851      0.005    -356.528     -65.362\n",
      "bmi          530.8222     80.093      6.628      0.000     373.207     688.437\n",
      "bp           312.5216     75.774      4.124      0.000     163.406     461.638\n",
      "s1          -535.9169    248.181     -2.159      0.032   -1024.314     -47.520\n",
      "s2           307.8250    265.404      1.160      0.247    -214.465     830.115\n",
      "s4           186.1348    139.385      1.335      0.183     -88.161     460.430\n",
      "s5           658.5669    139.757      4.712      0.000     383.539     933.595\n",
      "==============================================================================\n",
      "Omnibus:                        5.118   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.077   Jarque-Bera (JB):                3.867\n",
      "Skew:                           0.151   Prob(JB):                        0.145\n",
      "Kurtosis:                       2.542   Cond. No.                         126.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar R2_adj:\n",
    "modelo_backward_r2_adj, valor_backward_r2_adj = seleccion_paso_a_paso_atras(X_train, y_train, criterio='R2_adj', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "eaa73c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Mejor modelo según validacion =========\n",
      "  k = 7\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's2', 's4', 's5']\n",
      "  Métrica (validacion): 3062.6161\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.494\n",
      "Method:                 Least Squares   F-statistic:                     43.90\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.81e-42\n",
      "Time:                        18:21:35   Log-Likelihood:                -1664.2\n",
      "No. Observations:                 308   AIC:                             3344.\n",
      "Df Residuals:                     300   BIC:                             3374.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        149.2681      3.118     47.879      0.000     143.133     155.403\n",
      "sex         -210.9450     73.979     -2.851      0.005    -356.528     -65.362\n",
      "bmi          530.8222     80.093      6.628      0.000     373.207     688.437\n",
      "bp           312.5216     75.774      4.124      0.000     163.406     461.638\n",
      "s1          -535.9169    248.181     -2.159      0.032   -1024.314     -47.520\n",
      "s2           307.8250    265.404      1.160      0.247    -214.465     830.115\n",
      "s4           186.1348    139.385      1.335      0.183     -88.161     460.430\n",
      "s5           658.5669    139.757      4.712      0.000     383.539     933.595\n",
      "==============================================================================\n",
      "Omnibus:                        5.118   Durbin-Watson:                   1.924\n",
      "Prob(Omnibus):                  0.077   Jarque-Bera (JB):                3.867\n",
      "Skew:                           0.151   Prob(JB):                        0.145\n",
      "Kurtosis:                       2.542   Cond. No.                         126.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación (debe tener los datos de validación):\n",
    "modelo_backward_val, mse_backward_val = seleccion_paso_a_paso_atras(X_train, y_train, criterio='validacion', X_val=X_val, y_val=y_val, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "d4fd91d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mejor modelo según CV ===\n",
      "  k = 8\n",
      "  Predictores: ['sex', 'bmi', 'bp', 's1', 's2', 's4', 's5', 's6']\n",
      "  Mejor MSE en CV: 2639.5306\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.497\n",
      "Model:                            OLS   Adj. R-squared:                  0.484\n",
      "Method:                 Least Squares   F-statistic:                     38.03\n",
      "Date:                Mon, 12 May 2025   Prob (F-statistic):           8.96e-42\n",
      "Time:                        18:21:36   Log-Likelihood:                -1718.3\n",
      "No. Observations:                 317   AIC:                             3455.\n",
      "Df Residuals:                     308   BIC:                             3488.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        150.1885      3.122     48.113      0.000     144.046     156.331\n",
      "sex         -221.5334     73.247     -3.024      0.003    -365.660     -77.406\n",
      "bmi          532.6945     78.526      6.784      0.000     378.179     687.210\n",
      "bp           266.6735     78.859      3.382      0.001     111.504     421.843\n",
      "s1          -552.3222    246.717     -2.239      0.026   -1037.787     -66.857\n",
      "s2           295.4498    263.310      1.122      0.263    -222.664     813.564\n",
      "s4           108.3904    141.915      0.764      0.446    -170.855     387.636\n",
      "s5           705.3575    145.402      4.851      0.000     419.251     991.464\n",
      "s6            49.7172     79.081      0.629      0.530    -105.891     205.325\n",
      "==============================================================================\n",
      "Omnibus:                        1.383   Durbin-Watson:                   2.102\n",
      "Prob(Omnibus):                  0.501   Jarque-Bera (JB):                1.307\n",
      "Skew:                           0.038   Prob(JB):                        0.520\n",
      "Kurtosis:                       2.695   Cond. No.                         125.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Usar validación cruzada con k=5:\n",
    "modelo_backward_cv, mse_backward_cv = seleccion_paso_a_paso_atras(pd.concat([X_train, X_val], axis=0), np.concatenate([y_train, y_val]), criterio='cv', k_cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbe7e8",
   "metadata": {},
   "source": [
    "# Métodos de Penalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff756f",
   "metadata": {},
   "source": [
    "Es muy importante estandarizar los datos, ya que tanto el Ridge Regression como el LASSO son muy sensibles a la escala. \n",
    "\n",
    "NOTA: El parámetro $\\lambda$ se llama alpha en Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "e51c5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28e269",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
